{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMc3Kzws4eCq",
        "outputId": "2e8d5da7-d145-4b1f-9552-0d966a1a81ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_1 = 'Can I take your key?'\n",
        "\n",
        "classifier(txt_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J54618KY591b",
        "outputId": "5d8249b4-a3bb-4e3e-f150-9347db35e34b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.996327817440033}]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_2 = 'Neutral sentanse'\n",
        "\n",
        "classifier(txt_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-toMtQn59x1",
        "outputId": "a8e5e5d4-dbed-4a25-a03a-69efb026f507"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9839417338371277}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygcD4o7p6Bmr",
        "outputId": "4abdf011-721a-4298-9050-0ab4ef31ed2e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_99']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer([txt_1, txt_2])"
      ],
      "metadata": {
        "id": "fN6A4VqY6CsU"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki84X82r6EHJ",
        "outputId": "120f13e8-3dd4-43c8-a2f4-fa8d022a319c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2064, 1045, 2202, 2115, 3145, 1029, 102], [101, 8699, 2741, 6962, 2063, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_with_padding = tokenizer([txt_1, txt_2], padding = True, truncation = True, max_length = 256, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "dDe98hg66FVD"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_with_padding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnCKXLTq6GYz",
        "outputId": "4432139a-ee8e-4636-a015-1c467a8e025d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
              "array([[ 101, 2064, 1045, 2202, 2115, 3145, 1029,  102],\n",
              "       [ 101, 8699, 2741, 6962, 2063,  102,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(**inputs_with_padding).logits"
      ],
      "metadata": {
        "id": "RUcbcxsGDVL7"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzvwg3EPDaNA",
        "outputId": "34982741-7167-4271-cc70-264827ae5269"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[ 3.089482 , -2.5138037],\n",
              "       [ 2.2197464, -1.895595 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs_with_padding)"
      ],
      "metadata": {
        "id": "i-aAhrKC6HoV"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJpdkW3A6I2T",
        "outputId": "01e88f92-d955-4852-aa98-4d96f167eeb2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[ 3.089482 , -2.5138037],\n",
              "       [ 2.2197464, -1.895595 ]], dtype=float32)>, hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "predictions = tf.nn.softmax(outputs[0], axis=-1)\n",
        "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n",
        "model.config.id2label[predicted_class_id]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E0IHPBDm6J6z",
        "outputId": "a4c1b430-be8b-4182-a5fc-2fa8e11e15da"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF6WaQCw6w6T",
        "outputId": "1ba0b002-04e9-4ddb-e2ed-4d06929aa30b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[0.9963278 , 0.0036722 ],\n",
              "       [0.98394173, 0.0160583 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ]
}